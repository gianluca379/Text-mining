import os
import re
import warnings
import numpy as np
import pandas as pd
import faiss
from sentence_transformers import SentenceTransformer

warnings.filterwarnings("ignore")

# =====================================================
# 1. RUTAS
# =====================================================
DATA_PATH = "Car_Reviews_espa√±ol.xlsx"
EMB_PATH = "car_reviews_embeddings.npy"

# =====================================================
# 2. CARGA DE DATOS
# =====================================================
if not os.path.exists(DATA_PATH):
    raise FileNotFoundError(
        f"No se encontr√≥ el archivo {DATA_PATH}. Subilo al mismo repo/carpeta donde est√° app.py."
    )

df = pd.read_excel(DATA_PATH)
df = df.dropna(subset=["review_es"])

documents = [
    f"Veh√≠culo: {row['Vehicle_Title']}. Comentario del usuario: {row['review_es']}. ¬øLo recomienda?: {row['Recommend']}."
    for _, row in df.iterrows()
]

ALL_TITLES_LOW = df["Vehicle_Title"].str.lower()

print(f"‚úÖ Dataset cargado: {len(df)} rese√±as")

# =====================================================
# 3. EMBEDDINGS + FAISS
# =====================================================
print("Cargando modelo de SentenceTransformer - all-MiniLM-L6-v2 ...")
embedding_model = SentenceTransformer("all-MiniLM-L6-v2")
EMB_DIM = 384
print("Modelo cargado ‚úÖ")

if os.path.exists(EMB_PATH):
    doc_embeddings = np.load(EMB_PATH)
    print(f"Embeddings cargados desde {EMB_PATH}")
else:
    print("Generando embeddings (primera vez)...")
    doc_embeddings = embedding_model.encode(documents, show_progress_bar=False)
    doc_embeddings = np.array(doc_embeddings, dtype="float32")
    try:
        np.save(EMB_PATH, doc_embeddings)
    except Exception:
        pass
    print("‚úÖ Embeddings generados y guardados")

doc_embeddings = np.array(doc_embeddings, dtype="float32")

index = faiss.IndexFlatL2(EMB_DIM)
index.add(doc_embeddings)
print(f"√çndice FAISS creado con {index.ntotal} vectores.")

# =====================================================
# 4. LISTAS / EXPANSIONES
# =====================================================
KNOWN_BRANDS = ["toyota", "ford", "hyundai", "kia", "honda", "chevrolet", "chevy"]

STOP_TOKENS = {
    "la", "el", "de", "del", "los", "las", "y", "sobre", "que",
    "una", "un", "al", "en", "para", "por", "con", "lo"
}

# palabras que disparan expansi√≥n sem√°ntica
QUERY_EXPANSIONS = {
    "caja autom√°tica": ["transmisi√≥n", "transmision", "caja", "automatic"],
    "consumo": [
        "consumo", "combustible", "consumo de combustible",
        "mpg", "gasolina", "rendimiento de gasolina",
        "econom√≠a de combustible", "kilometraje", "millas", "km"
    ],
    "ruido": ["ruido", "ruidoso", "cabina ruidosa", "sound", "noise"],
}

# aspecto ‚Üí palabras que tienen que aparecer
ASPECT_EXPANSIONS = {
    "consumo": [
        "consumo", "combustible", "consumo de combustible",
        "gasolina", "rendimiento", "mpg", "econom√≠a", "economia", "millas", "km"
    ],
    "ruido": ["ruido", "ruidoso", "sonido", "cabina ruidosa"],
    "transmisi√≥n": ["transmisi√≥n", "transmision", "caja", "caja autom√°tica", "automatic"],
    "motor": ["motor", "potencia", "engine"],
    "espacio": ["espacio", "carga", "maletero", "ba√∫l", "baul"],
    "aire": ["aire acondicionado", "ac", "a/c", "climatizador"],
}


# =====================================================
# 5. HELPERS
# =====================================================
def clean_token(t: str) -> str:
    return re.sub(r'^[\?\!\.\,\;\:\¬ø\¬°]+|[\?\!\.\,\;\:\¬ø\¬°]+$', '', t)

def expand_query(query: str) -> str:
    q = query.lower()
    extra = []
    for key, vals in QUERY_EXPANSIONS.items():
        if key in q:
            extra.extend(vals)
    return query + " " + " ".join(extra) if extra else query

def has_query_year(query: str) -> str | None:
    m = re.search(r"\b(19|20)\d{2}\b", query)
    return m.group(0) if m else None

def context_has_year(context: str, year: str) -> bool:
    return year in context

def get_aspect_terms(query: str):
    q = query.lower()
    terms = set()
    for key, vals in ASPECT_EXPANSIONS.items():
        if key in q:
            terms.update(vals)
    return list(terms)

def get_aspect_name(query: str) -> str | None:
    q = query.lower()
    for key in ASPECT_EXPANSIONS.keys():
        if key in q:
            return key
    return None

def rerank_by_aspect(docs: list[str], query: str) -> list[str]:
    aspect_terms = get_aspect_terms(query)
    if not aspect_terms:
        return docs
    scored = []
    for d in docs:
        low = d.lower()
        score = sum(low.count(term) for term in aspect_terms)
        scored.append((score, d))
    scored.sort(key=lambda x: x[0], reverse=True)
    return [d for _, d in scored]

def filter_docs_by_aspect(retrieved_docs: list[str], query: str) -> list[str]:
    aspect_terms = get_aspect_terms(query)
    if not aspect_terms:
        return retrieved_docs
    filtered = []
    for doc in retrieved_docs:
        sentences = re.split(r"[\.!?]\s+", doc)
        for sent in sentences:
            if any(term in sent.lower() for term in aspect_terms):
                filtered.append(sent.strip() + ".")
    return filtered


def extract_years_from_docs(docs: list[str]) -> list[str]:
    years = set()
    for d in docs:
        found = re.findall(r"\b(?:19|20)\d{2}\b", d)
        for y in found:
            years.add(y)
    return sorted(list(years))


# =====================================================
# 6. RETRIEVAL
# =====================================================
def retrieve_documents(query: str, k: int = 3):
    """
    Recupera k documentos lo m√°s alineados posible con la marca/modelo.
    """
    q_low = query.lower()
    tokens = [clean_token(t) for t in q_low.split() if clean_token(t)]
    brands_in_query = [b for b in KNOWN_BRANDS if b in q_low]

    # tokens que tambi√©n existen en los t√≠tulos
    model_like_tokens = []
    for t in tokens:
        if t in STOP_TOKENS or t in KNOWN_BRANDS:
            continue
        if ALL_TITLES_LOW.str.contains(t).any():
            model_like_tokens.append(t)

    # marca + modelo (m√°s preciso)
    if brands_in_query and model_like_tokens:
        mask = pd.Series([True] * len(df))
        mask &= df["Vehicle_Title"].str.lower().str.contains("|".join(brands_in_query))
        for tok in model_like_tokens:
            mask &= df["Vehicle_Title"].str.lower().str.contains(tok)
        df_sub = df[mask]
        if not df_sub.empty:
            df_sub = df_sub.reset_index(drop=True)
            return [
                f"Veh√≠culo: {row['Vehicle_Title']}. Comentario del usuario: {row['review_es']}. ¬øLo recomienda?: {row['Recommend']}."
                for _, row in df_sub.head(k).iterrows()
            ]

    # solo marca
    if brands_in_query:
        mask = df["Vehicle_Title"].str.lower().str.contains("|".join(brands_in_query))
        df_sub = df[mask]
        if not df_sub.empty:
            sub_docs = [
                f"Veh√≠culo: {row['Vehicle_Title']}. Comentario del usuario: {row['review_es']}. ¬øLo recomienda?: {row['Recommend']}."
                for _, row in df_sub.iterrows()
            ]
            sub_emb = embedding_model.encode(sub_docs, show_progress_bar=False)
            sub_emb = np.array(sub_emb, dtype="float32")
            sub_index = faiss.IndexFlatL2(EMB_DIM)
            sub_index.add(sub_emb)

            expanded_query = expand_query(query)
            q_emb = np.array(embedding_model.encode([expanded_query]), dtype="float32")
            _, idxs = sub_index.search(q_emb, min(k, len(sub_docs)))
            return [sub_docs[i] for i in idxs[0]]

    # global
    expanded_query = expand_query(query)
    q_emb = np.array(embedding_model.encode([expanded_query]), dtype="float32")
    _, idxs = index.search(q_emb, k)
    return [documents[i] for i in idxs[0]]


# =====================================================
# 7. CONSTRUCTOR DE RESPUESTA
# =====================================================
def build_human_answer(query: str, docs: list[str]) -> str:
    vehiculos = set()
    comentarios = []
    pos = 0
    neg = 0

    for d in docs:
        if d.startswith("Veh√≠culo:"):
            vh = d.split("Comentario del usuario:")[0]
            vh = vh.replace("Veh√≠culo:", "").strip().strip(".")
            vehiculos.add(vh)
        if "Comentario del usuario:" in d:
            com = d.split("Comentario del usuario:")[1]
            com = com.split("¬øLo recomienda?")[0].strip()
        else:
            com = d.strip()
        comentarios.append(com)

        if "¬øLo recomienda?: Si" in d or "¬øLo recomienda?: S√≠" in d:
            pos += 1
        elif "¬øLo recomienda?: No" in d:
            neg += 1

    resp = "Esto es lo que dicen las rese√±as encontradas:\n\n"
    if vehiculos:
        resp += "Modelos con opiniones: " + ", ".join(vehiculos) + ".\n"
    if pos or neg:
        total = pos + neg
        resp += f"De {total} opiniones, {pos} son positivas y {neg} son negativas.\n"
    resp += "\nPrincipales comentarios:\n"
    for c in comentarios[:3]:
        resp += f"- {c}\n"
    return resp.strip()


# =====================================================
# 8. PIPELINE FINAL
# =====================================================
def answer_pipeline(query: str, k: int = 3) -> str:
    """
    k = lo que pide el usuario (lo que se muestra).
    internamente vamos a recuperar m√°s (8) para poder filtrar por consumo/ruido/etc.
    """
    internal_k = max(k, 8)  # üëà ac√° est√° la mejora
    docs = retrieve_documents(query, k=internal_k)
    docs = rerank_by_aspect(docs, query)

    # si pidi√≥ a√±o concreto y no hay
    year = has_query_year(query)
    ctx = "\n\n".join(docs)
    if year and not context_has_year(ctx, year):
        yrs = extract_years_from_docs(docs)
        if yrs:
            return (
                f"No encuentro rese√±as del {year}.\n"
                f"Pero s√≠ hay opiniones de estos a√±os: {', '.join(yrs)}.\n"
                "¬øQuer√©s que te cuente sobre alguno de esos?"
            )
        else:
            return (
                f"No encuentro rese√±as del {year}. "
                "Solo hay comentarios de otros a√±os o modelos."
            )

    # filtrar por aspecto
    aspect_docs = filter_docs_by_aspect(docs, query)
    aspect_name = get_aspect_name(query)

    if get_aspect_terms(query) and not aspect_docs:
        # hab√≠a un aspecto (consumo/ruido/motor) pero las rese√±as que llegaron no hablan de eso
        return (
            f"No encontr√© comentarios espec√≠ficos sobre **{aspect_name}** para este modelo en las rese√±as recuperadas.\n"
            "Pero s√≠ hablan de otras cosas (comodidad, espacio, manejo, etc.). Pod√©s probar con otra pregunta o ampliar el modelo/a√±o."
        )

    # quedate solo con lo que el usuario pidi√≥ ver
    final_docs = aspect_docs if aspect_docs else docs
    final_docs = final_docs[:k]

    return build_human_answer(query, final_docs)


def retrieve_for_ui(query: str, k: int = 3):
    # lo dejamos simple para la app
    return retrieve_documents(query, k=k)
